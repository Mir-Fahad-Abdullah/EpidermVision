# -*- coding: utf-8 -*-
"""skin_disease_detection_efficientnetB0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f1lAukK5iLHM97oUK3vNnB9IPR__8Dn9

# Mount Google Drive in Google Colab
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Install necessary packages"""

!pip install efficientnet

!pip install tensorflow scikit-learn matplotlib

"""# Import necessary libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import time
from sklearn.metrics import classification_report, confusion_matrix
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from keras.layers import concatenate
from keras.optimizers import Adam
from keras.models import Model, Sequential, load_model
from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from efficientnet.tfkeras import EfficientNetB0
from keras.utils import plot_model
from keras.layers import BatchNormalization, LeakyReLU

"""# Define paths and constants"""

data_dir = '/content/drive/MyDrive/ISIC_Labelled'
test_data_dir = '/content/drive/MyDrive/test_dataset'

input_shape = (300, 300, 3)
num_classes = 8
epochs = 30
batch_size = 32

"""# Data preprocessing and augmentation"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

valid_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='categorical')

valid_generator = valid_datagen.flow_from_directory(
    data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='categorical')

"""# Define EfficientNet model"""

base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(300, 300, 3), classes=8)

"""# Define custom model"""

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),  # Increased dropout rate for better regularization
    Dense(1024),
    BatchNormalization(),  # Adding Batch Normalization
    LeakyReLU(),  # Using Leaky ReLU activation function
    Dropout(0.5),
    Dense(512),  # Additional Dense layer
    BatchNormalization(),
    LeakyReLU(),
    Dropout(0.5),
    Dense(8, activation='softmax')
])

"""# View Model Summary & Plot"""

model.summary()
plot_model(model, show_shapes=True, show_layer_names=True)

"""# Define optimizer, learning rate scheduler, and early stopping"""

optimizer = Adam(learning_rate=0.0001)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

"""# Compile & Train the model"""

model.compile(loss="categorical_crossentropy", optimizer=optimizer, metrics=['accuracy'])

start_time = time.time()
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=epochs,
    validation_data=valid_generator,
    validation_steps=valid_generator.samples // valid_generator.batch_size,
    verbose=1,
    callbacks=[lr_scheduler, early_stopping]
)
end_time = time.time()
training_time = end_time - start_time

"""# Training time"""

total_time = training_time / 60
time_per_epoch = total_time / epochs
print(f"Time per epoch: {time_per_epoch} minutes")
print(f"Total time for training: {total_time} minutes")

"""# Calculate the Loss and Accuracy on the Validation Data"""

test_loss, test_acc = model.evaluate(test_generator)
print('test accuracy : ', test_acc)

"""# Saving the model prediction on a csv file"""

# Generate predictions
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions, axis=1)

# Get filenames and true labels from the test generator
filenames = test_generator.filenames
true_classes = test_generator.classes

# Creating a DataFrame with filenames, true labels, and predicted labels
results_df = pd.DataFrame({'Filename': filenames,
                           'True Class': true_classes,
                           'Predicted Class': predicted_classes})

# Saving the DataFrame to a CSV file
results_df.to_csv('/content/drive/MyDrive/test_dataset/test_predictions.csv', index=False)

print("Model predictions saved successfully.")

"""# Model Evaluation"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

"""# Plot Training and Validation Accuracy & Loss"""

plt.figure(figsize=(12, 6))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

plt.tight_layout()
plt.show()

"""# Classification Report"""

predictions = model.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

print(classification_report(y_true, y_pred, target_names=class_labels))

"""# Confusion Matrix"""

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""# Correlation Heatmap"""

corr = np.corrcoef(predictions.T)
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Classes')
plt.ylabel('Classes')
plt.title('Correlation Heatmap of Classes')
plt.show()